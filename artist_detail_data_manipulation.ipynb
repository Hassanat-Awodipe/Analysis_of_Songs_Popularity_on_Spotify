{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d900b1f-931e-4d39-a647-facd1958cca7",
      "metadata": {
        "id": "4d900b1f-931e-4d39-a647-facd1958cca7"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from pprint import pprint as pp\n",
        "import spotipy\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "import pandas as pd\n",
        "import re\n",
        "import country_converter as coco\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import wptools as wp\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service as ChromeService\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from random import uniform\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "from statistics import median\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "143ce571-8d7f-46e1-909f-03049a155987",
      "metadata": {
        "id": "143ce571-8d7f-46e1-909f-03049a155987"
      },
      "source": [
        "#Data Source B: \n",
        "More artist informtion from Wikipedia and Kaggle - artist personal details"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c73acb56-249f-47f0-8cd0-aba0f3d20991",
      "metadata": {
        "id": "c73acb56-249f-47f0-8cd0-aba0f3d20991"
      },
      "source": [
        "Step1a: Scrap artist's birthday, birth place from Wikipedia "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fa09022-a791-4218-a8fc-df4098e8ed56",
      "metadata": {
        "id": "3fa09022-a791-4218-a8fc-df4098e8ed56"
      },
      "outputs": [],
      "source": [
        "# the above csv file was cleaned to enable the artist name match how it is recorded in Wikipedia\n",
        "music = pd.read_csv('track artist audio features cleaned.csv')\n",
        "\n",
        "# drop duplicate index column\n",
        "music.drop('Unnamed: 0', axis=1, inplace=True)  \n",
        "\n",
        "# isolate artist id and name\n",
        "music = music[['artist_id', 'artist_name']]\n",
        "\n",
        "# drop duplicate artist\n",
        "music.drop_duplicates(inplace=True)\n",
        "music"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into groups because wiki has a time limit for scraping\n",
        "# this is the error for time limit: (28, 'Failed to connect to en.wikipedia.org port 443 after 21022 ms: Timed out')\n",
        "# first group\n",
        "music_first = music[:800].copy()\n",
        "\n",
        "# second group\n",
        "music_second = music[800:1600].copy()  \n",
        "\n",
        "# third group\n",
        "music_third = music[1601:2400].copy()\n",
        "\n",
        "# fourth group\n",
        "music_fourth = music[2400:].copy()"
      ],
      "metadata": {
        "id": "75aFYquGeize"
      },
      "id": "75aFYquGeize",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for scraping singer_details and saving to a df\n",
        "def scrape_infobox(df_name):\n",
        "    '''\n",
        "    This function scrapes the infobox of artists from wikipedia and \n",
        "    appends the data as new columns to the dataframe\n",
        "    '''\n",
        "    count = 0 \n",
        "    for index, each_name in zip(df_name.index, df_name['artist_name']):\n",
        "        count += 1\n",
        "        print(str(count) + \": \" + each_name)\n",
        "        try:\n",
        "            page = wp.page(each_name).get_parse()\n",
        "            keys = ['name', 'members', 'current_members', 'birth_name', 'origin', 'birth_place', 'birth_date']\n",
        "            if keys[0] in page.data['infobox'].keys():  # artist name\n",
        "                df_name.loc[index, 'name']= page.data['infobox'][keys[0]]\n",
        "            else:\n",
        "                df_name.loc[index, 'name'] = np.nan\n",
        "\n",
        "            if keys[1] in page.data['infobox'].keys():  # bands members name\n",
        "                df_name.loc[index, 'members'] = page.data['infobox'][keys[1]]\n",
        "            elif keys[2] in page.data['infobox'].keys():\n",
        "                df_name.loc[index, 'members'] = page.data['infobox'][keys[2]]\n",
        "            else:\n",
        "                df_name.loc[index, 'members'] = np.nan\n",
        "\n",
        "            if keys[1] in page.data['infobox'].keys():  # members for bands\n",
        "                df_name.loc[index, 'band'] = 'True'\n",
        "            elif keys[2] in page.data['infobox'].keys():\n",
        "                df_name.loc[index, 'band'] = 'True'\n",
        "            else:\n",
        "                df_name.loc[index, 'band'] = 'False'\n",
        "\n",
        "            if keys[3] in page.data['infobox'].keys():  # artist birth name\n",
        "                df_name.loc[index, 'birth_name'] = page.data['infobox'][keys[3]]\n",
        "            else:\n",
        "                df_name.loc[index, 'birth_name'] = np.nan\n",
        "\n",
        "            if keys[4] in page.data['infobox'].keys():  # nationality\n",
        "                df_name.loc[index, 'birth_place'] = page.data['infobox'][keys[4]]\n",
        "            elif keys[5] in page.data['infobox'].keys():\n",
        "                df_name.loc[index, 'birth_place'] = page.data['infobox'][keys[5]]\n",
        "            else:\n",
        "                df_name.loc[index, 'birth_place'] = np.nan\n",
        "\n",
        "            if keys[6] in page.data['infobox'].keys():  # age\n",
        "                df_name.loc[index, 'birth_date'] = page.data['infobox'][keys[6]]\n",
        "            else:\n",
        "                df_name.loc[index, 'birth_date'] = np.nan\n",
        "\n",
        "        except AttributeError as err:\n",
        "            pass\n",
        "        except TypeError as err:\n",
        "            pass\n",
        "        except LookupError as err1:\n",
        "            pass\n",
        "        except ValueError as err2:\n",
        "            pass   \n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "Xb4AfaRWfs86"
      },
      "id": "Xb4AfaRWfs86",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scrape data for artist groups individually \n",
        "music_first = scrape_infobox(df_name=music_first)\n",
        "music_second = scrape_infobox(df_name=music_second)\n",
        "music_third = scrape_infobox(df_name=music_third)\n",
        "music_fourth = scrape_infobox(df_name=music_fourth)"
      ],
      "metadata": {
        "id": "fNiU7w8Xf5aQ"
      },
      "id": "fNiU7w8Xf5aQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine the artist groups vertically into one dataframe\n",
        "artist_details_combined = pd.concat([music_first, music_second, music_third, music_fourth])"
      ],
      "metadata": {
        "id": "PUAf7RJIhSG_"
      },
      "id": "PUAf7RJIhSG_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actually, the scraping shouldnt be done in the below manner, i.e saving to four different csv. so we wrote a code(above ) that scrapes then combines the df into one before saving to a csv. (If we leave this here we will be shooting ourselves in the leg)"
      ],
      "metadata": {
        "id": "mjBgp8GOdQBx"
      },
      "id": "mjBgp8GOdQBx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3d398c8-60b1-4b9a-9697-4f83b6a7b780",
      "metadata": {
        "id": "f3d398c8-60b1-4b9a-9697-4f83b6a7b780"
      },
      "outputs": [],
      "source": [
        "# #The artist details were saved to 4 different files due to wikipedia's respond time.\n",
        "# df1 = pd.read_csv('artist1.csv', encoding='utf-8')\n",
        "# df2 = pd.read_csv('artist2.csv', encoding='utf-8')\n",
        "# df3 = pd.read_csv('artist3.csv', encoding='utf-8')\n",
        "# df4 = pd.read_csv('artist4.csv', encoding='utf-8')\n",
        "\n",
        "# #To vertically combine all the files\n",
        "# df_artist = pd.concat([df1, df2, df3, df4], axis=0)\n",
        "# #save the artist details to a file.\n",
        "# df_artist.to_csv('artist_details_combined.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d082bd0c-b83c-4041-a955-aff42b40345c",
      "metadata": {
        "id": "d082bd0c-b83c-4041-a955-aff42b40345c"
      },
      "source": [
        "(Step1c): Name clashes on different artists was discovered later, by that time we already started scraping artists' detail from Wikipedia, hence we take the drop_list value from our previous cell and repeat this process with artist_details_combined.csv \n",
        "\n",
        "Name the file artist_details_unique_artist_name.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb3653df-c270-4322-b395-58bdb62b86ef",
      "metadata": {
        "id": "bb3653df-c270-4322-b395-58bdb62b86ef"
      },
      "outputs": [],
      "source": [
        "# drop_list from previous cells, the value was printed and stored, so that we can use it without running the code again\n",
        "drop_list = ['7lf4M8KM02hIiVGHKsAl2o', '6h9telSBnbabV6eyeQtWO7', '0mZsmXegjYM7hNw0QGE5b7', '2uFUBdaVGtyMqckSeCl0Qj', '68abRTdO4meYReMWHvBYb0', '02J7bo06ZZ1XmSGochlWak', '0hDmcvucqFYoojOpHfDiZ0', '4pchWejl1hLpJ8zXvZlqLb', '6GDDxhe281I5aNSgCYphex', '7n2Ycct7Beij7Dj7meI4X0', '7EXJJpgDl7y4szvrpUYj0s', '3a0gvZAydt98HKVbGb0V67', '0hEurMDQu99nJRq8pTxO14', '0ZkhUsUWbgsB356AUiiIWz', '3TOqt5oJwL9BE2NG9MEwDa', '2m1l9MLSslzup4vvokKgvQ', '37SQDDbylULQMBCICskLdA', '536pTabXNhaK7O7VfjOk7P', '5o7lbGxFCLde3JqX2EKzjZ', '0a1pOwbTl7KjPdm9h7DJT5', '2yp6zqk49KOKKrOSSsUb75', '3EAHF3jdnHHdko5DBrhRUP']\n",
        "df = pd.read_csv('artist_details_combined.csv', encoding='utf-8')\n",
        "for row in df.index:\n",
        "    if df.loc[row, \"artist_id\"] in drop_list:\n",
        "        df.drop(row, inplace=True)\n",
        "df.to_csv('artist_details_unique_artist_name.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a46732c8-2377-4896-adc3-a680020f0123",
      "metadata": {
        "id": "a46732c8-2377-4896-adc3-a680020f0123"
      },
      "source": [
        "Step2: Combine gender dataset from Kaggle with artist details from Wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read the gender data downloaded from Kaggle\n",
        "gender_df = pd.read_csv('singers_gender.csv', encoding='latin1')\n",
        "\n",
        "# read the artist details with unique artist name csv\n",
        "artist = pd.read_csv('artist_details_unique_artist_name.csv')"
      ],
      "metadata": {
        "id": "BwBawFBDkAUf"
      },
      "id": "BwBawFBDkAUf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2d136e2-e294-43cb-bb47-0f9aad4fd002",
      "metadata": {
        "id": "f2d136e2-e294-43cb-bb47-0f9aad4fd002"
      },
      "outputs": [],
      "source": [
        "# combine the above datasets on the artist_name column using a left join\n",
        "artists_detail_with_category = artist.merge(gender_df, how='left', left_on='artist_name', right_on='artist')\n",
        "\n",
        "# save the above df to csv\n",
        "artists_detail_with_category.to_csv('artists_detail_with_category.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96458328-ce03-4a62-bdfb-87d91ee641b2",
      "metadata": {
        "id": "96458328-ce03-4a62-bdfb-87d91ee641b2"
      },
      "source": [
        "Step3: Organising the data\n",
        "\n",
        "We need to convert birth place information into birth country, and convert birthday into birth year.\n",
        "\n",
        "Country:\n",
        "\n",
        "We will be using a python package called country_converter (coco) to extract country information. \n",
        "\n",
        "However, some astist's country information is missing on Wikipedia but available in the Kaggle dataset. The information from Wikipedia could be unorganised, e.g. for multicultural artists the way Wikipedia store the information could be inconsistent, for many artists from the US it's showing the state but not the country name. \n",
        "\n",
        "There is not a python package that could fetch city or state information to convert it into country, so we extract country information from Kaggle (column 'category') first, and overwrite it to the data from Wikipedia (column 'birth_place'). Then we go through column 'birth_place'.\n",
        "\n",
        "Birth year:\n",
        "\n",
        "To simplify the process, we convert birth_date to birth_year at the same time. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d84571c-f77b-4507-8006-ba69079ee3d1",
      "metadata": {
        "id": "5d84571c-f77b-4507-8006-ba69079ee3d1"
      },
      "source": [
        "Step3a: \n",
        "\n",
        "\n",
        "Convert birth_date to birth_year. \n",
        "\n",
        "\n",
        "Overwrite country information extracted from Kaggle to Wikipedia \n",
        "\n",
        "\n",
        "Save the process into artist_category_to_more.csv \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ba42381-b326-48d6-8312-d5405cde4809",
      "metadata": {
        "id": "0ba42381-b326-48d6-8312-d5405cde4809"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('artists_detail_with_category.csv', encoding='utf-8')\n",
        "df = df.sort_values(by=['category'], ascending=True)\n",
        "\n",
        "for row in df.index:\n",
        "    artist_category = str(df.loc[row, 'category'])\n",
        "    if artist_category == 'nan':\n",
        "        # print('break')\n",
        "        break\n",
        "    else:\n",
        "        \n",
        "        # some of the variations and counties can't be recognized by country_converter\n",
        "        if 'American' in artist_category:\n",
        "            df.loc[row, 'birth_place'] = 'United States'\n",
        "        elif 'Canadian' in artist_category:\n",
        "            df.loc[row, 'birth_place'] = 'Canada'\n",
        "        elif any(c in artist_category for c in ('British', 'English', 'Scottish', 'Welsh')):\n",
        "            df.loc[row, 'birth_place'] = 'United Kingdom'\n",
        "            print('uk')\n",
        "        else:\n",
        "            artist_country = coco.convert(artist_category, to='name_short')\n",
        "            if artist_country != 'not found':\n",
        "                df.loc[row, 'birth_place'] = artist_country\n",
        "                print(artist_country)\n",
        "\n",
        "#to get only the birth year of the artists\n",
        "df['birth_year'] = df['birth_date'].str.extract(r'(\\d{4})')\n",
        "\n",
        "df.to_csv('artist_category_to_more.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "822485f0-8ff1-4e3c-a9ab-256cd2406697",
      "metadata": {
        "id": "822485f0-8ff1-4e3c-a9ab-256cd2406697"
      },
      "source": [
        "Step3b: Extract all the country information and store it in artist_country column \n",
        "\n",
        "\n",
        "Save it in artists_details_final.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e020719-323b-465a-b1f7-b400166074da",
      "metadata": {
        "id": "7e020719-323b-465a-b1f7-b400166074da"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('artist_category_to_more.csv', encoding='utf-8')\n",
        "artist_country_dic = {}\n",
        "\n",
        "birth_place_list = df['birth_place'].tolist()\n",
        "birth_place_list = list(set(birth_place_list))\n",
        "\n",
        "for birth_place in birth_place_list:\n",
        "    artist_country = []\n",
        "    bp = re.sub('[^A-Za-z ,]+', '', str(birth_place)).split(',')\n",
        "    for element_raw in bp:\n",
        "        element = element_raw.strip()\n",
        "        \n",
        "        # some of the variations and counties can't be recognized by country_converter  \n",
        "        if element in ('England', 'Scotland', 'Wales', 'Northern Ireland', 'UK'):\n",
        "            artist_country.append('United Kingdom')\n",
        "        elif element == 'U.S.':\n",
        "            artist_country.append('United State')\n",
        "        else:\n",
        "            country = coco.convert(element, to='name_short')\n",
        "            if country != 'not found':\n",
        "                if type(country) == list:\n",
        "                    for c in country:\n",
        "                        artist_country.append(c)\n",
        "                else:\n",
        "                    artist_country.append(country)\n",
        "\n",
        "    if len(artist_country) > 1:\n",
        "        artist_country_cleaned = []\n",
        "        for ac in artist_country:\n",
        "            if ac not in artist_country_cleaned:\n",
        "                artist_country_cleaned.append(ac)\n",
        "                \n",
        "        # remove error due to (comonents in) city/state name clashes country name\n",
        "        if 'United States' in artist_country_cleaned:\n",
        "            if 'Georgia' in artist_country_cleaned:\n",
        "                artist_country_cleaned.remove('Georgia')\n",
        "            if 'Jersey' in artist_country_cleaned:\n",
        "                artist_country_cleaned.remove('Jersey')\n",
        "        if 'Trinidad and Tobago' in artist_country_cleaned:\n",
        "            if 'Spain' in artist_country_cleaned:\n",
        "                artist_country_cleaned.remove('Spain')\n",
        "        artist_country = artist_country_cleaned\n",
        "\n",
        "    if len(artist_country) == 1:\n",
        "        artist_country_dic[birth_place] = artist_country[0]\n",
        "    elif len(artist_country) == 0:\n",
        "        artist_country_dic[birth_place] = 'N/A'\n",
        "    else:\n",
        "        artist_country_dic[birth_place] = 'multicultural'\n",
        "\n",
        "df['artist_country'] = df['birth_place'].map(artist_country_dic)\n",
        "\n",
        "df.to_csv('artists_details_final.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "name": "artist_detail_data_manipulation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}