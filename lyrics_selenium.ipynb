{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b93dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from random import uniform\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594bd53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMEDRIVER_PATH = '/Users/alisayanovski/Programming/drivers/chromedriver'\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "service = ChromeService(executable_path=CHROMEDRIVER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "35465a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get songs list as DataFrame\n",
    "\n",
    "songs_data = pd.read_csv('track_artist_audio_features_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "24ae914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract artist name and song name information, save them as tuples to a list\n",
    "\n",
    "songs_list = []\n",
    "\n",
    "for i in range(len(songs_data)):\n",
    "    artist_name = songs_data.loc[i]['artist_name']\n",
    "    song = songs_data.loc[i]['song']\n",
    "    songs_list.append([artist_name, song])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f622621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for scraping each song\n",
    "\n",
    "START_URL = 'https://www.azlyrics.com'\n",
    "QUERY_SELECTOR = '#q'\n",
    "SONG_LINK_SELECTOR = '.panel table > tbody:first-child a'\n",
    "LYRICS_SELECTOR = '.col-xs-12.col-lg-8.text-center div:nth-of-type(5)'\n",
    "\n",
    "def get_lyrics(artist_name, song):\n",
    "    '''\n",
    "    Takes as parameters two strings: artist_name and song.\n",
    "    Returnes text of the lyrics for this artist \n",
    "    '''\n",
    "    query = f'{artist_name.casefold()} {song.casefold()}'\n",
    "\n",
    "    try:\n",
    "        # go to the webpage\n",
    "        driver.get(START_URL)\n",
    "        \n",
    "        # wait random time to imitate user behaviour\n",
    "        time.sleep(uniform(2, 5))\n",
    "\n",
    "        # write and send a query in a search field\n",
    "        input_el = WebDriverWait(driver, 10).until(\n",
    "                   EC.presence_of_element_located((By.CSS_SELECTOR, QUERY_SELECTOR)))\n",
    "        input_el.send_keys(query + Keys.ENTER)\n",
    "\n",
    "        # wait\n",
    "        time.sleep(uniform(2, 5))\n",
    "        \n",
    "        # get first element of the search result and click the link\n",
    "        song_link = WebDriverWait(driver, 10).until(\n",
    "                   EC.presence_of_element_located((By.CSS_SELECTOR, SONG_LINK_SELECTOR)))\n",
    "\n",
    "        song_link.click()\n",
    "        \n",
    "        # wait\n",
    "        time.sleep(uniform(7, 12))\n",
    "\n",
    "        # get the page with lyrics and save the text\n",
    "        soup = BeautifulSoup(driver.page_source)        \n",
    "        text = soup.select(LYRICS_SELECTOR)[0].text\n",
    "\n",
    "        return text\n",
    "    \n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "652f33cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate webdriver\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# get the lyrics from the website and put into a list\n",
    "lyrics = []\n",
    "\n",
    "for artist_name, song in songs_list:\n",
    "    text = get_lyrics(artist_name, song)\n",
    "    lyrics.append((artist_name, song, text))\n",
    "\n",
    "# quit the driver    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b31fa29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe, clean empty values and save to a file\n",
    "\n",
    "df_lyrics = pd.DataFrame(lyrics, columns=['artist_name', 'song', 'lyrics'])\n",
    "cleaned_lyrics = df_lyrics[df_lyrics['lyrics'] != '']\n",
    "cleaned_lyrics.to_csv('lyrics_selenium.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce888b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge lyrics with the rest of information\n",
    "\n",
    "ids_part = songs_data[['artist_name', 'artist_id', 'song', 'track_id']]\n",
    "ids_part_merged = pd.merge(cleaned_lyrics, ids_part, on=['artist_name', 'song'], how='left')\n",
    "no_duplicates_df = ids_part_merged.dropna().drop_duplicates(subset=['artist_name', 'song'])\n",
    "\n",
    "no_duplicates_df.to_csv('final_csv.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
